{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3AaWaZKxH_T",
    "outputId": "c3f8ddfc-f811-4389-abd1-23384835c46a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.19.6)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.23.0,>=1.22.6 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.22.6)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.0,>=1.22.6->boto3) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.0,>=1.22.6->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.0,>=1.22.6->boto3) (1.15.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement re (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for re\u001b[0m\n",
      "Requirement already satisfied: spark-nlp==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "#Installed required configuration\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
    "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
    "\n",
    "!pip install -q findspark\n",
    "!pip install boto3\n",
    "!pip install re\n",
    "!pip install spark-nlp==3.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "y_Q-E71mx9aD"
   },
   "outputs": [],
   "source": [
    "#Create spark session\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YHsTIY_qcjSy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dDw5WC5Nyz-P"
   },
   "outputs": [],
   "source": [
    "#Import the dataset\n",
    "\n",
    "sqlContext = SQLContext(spark)\n",
    "pdf = pd.read_excel('Corona_NLP_train.xlsx')\n",
    "dataset = sqlContext.createDataFrame(pdf.astype(str))\n",
    "dataset = dataset.select('OriginalTweet','Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7XvnkOCwGk6X"
   },
   "outputs": [],
   "source": [
    "#Create NLP Pipline\n",
    "\n",
    "#Stages\n",
    "tokenizer_originalTweet = Tokenizer(inputCol='OriginalTweet', outputCol='originalTweet_tokens')\n",
    "stopwords_remover_originalTweet = StopWordsRemover(inputCol='originalTweet_tokens', outputCol='filtered_originalTweet')\n",
    "vectorizer_originalTweet = CountVectorizer(inputCol=\"filtered_originalTweet\",outputCol=\"raw_features_originalTweet\")\n",
    "idf_originalTweet = IDF(inputCol='raw_features_originalTweet', outputCol='vectorized_features_originalTweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ngc39U5KMygw"
   },
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "labelEncoder = StringIndexer(inputCol='Sentiment', outputCol='label').fit(dataset)\n",
    "dataset = labelEncoder.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hyDr--kzN3GM"
   },
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "(train_df, test_df) = dataset.randomSplit((0.7,0.3),seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "on-fsiy2dGjQ"
   },
   "outputs": [],
   "source": [
    "#Building pipeline\n",
    "lr = LogisticRegression(featuresCol='vectorized_features_originalTweet', labelCol='label')\n",
    "pipeline = Pipeline(stages=[tokenizer_originalTweet,stopwords_remover_originalTweet,vectorizer_originalTweet,idf_originalTweet,lr])\n",
    "lr_model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4afwL3MdiG9",
    "outputId": "ec6bf07a-5a2b-42bf-92eb-a63d74ac0d05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+--------------------+----------------------+--------------------------+---------------------------------+--------------------+--------------------+----------+\n",
      "|       OriginalTweet|         Sentiment|label|originalTweet_tokens|filtered_originalTweet|raw_features_originalTweet|vectorized_features_originalTweet|       rawPrediction|         probability|prediction|\n",
      "+--------------------+------------------+-----+--------------------+----------------------+--------------------------+---------------------------------+--------------------+--------------------+----------+\n",
      "|  A revised rail ...|          Positive|  0.0|[, , a, revised, ...|  [, , revised, rai...|      (93690,[0,5,46,88...|             (93690,[0,5,46,88...|[193.343478629558...|[1.0,3.0089464313...|       0.0|\n",
      "|  Consumer Alert ...|Extremely Negative|  4.0|[, , consumer, al...|  [, , consumer, al...|      (93690,[0,10,48,1...|             (93690,[0,10,48,1...|[-47.424499702330...|[3.89951836935118...|       2.0|\n",
      "|  Don t panic buy...|          Negative|  1.0|[, , don, t, pani...|  [, , panic, buy, ...|      (93690,[0,3,7,13,...|             (93690,[0,3,7,13,...|[-47.559896481670...|[2.82060845458674...|       1.0|\n",
      "|  Due to bharat b...|Extremely Positive|  3.0|[, , due, to, bha...|  [, , due, bharat,...|      (93690,[0,4,8,29,...|             (93690,[0,4,8,29,...|[60.0094099091120...|[2.86453028342291...|       1.0|\n",
      "|  Hazard pay for ...|          Negative|  1.0|[, , hazard, pay,...|  [, , hazard, pay,...|      (93690,[0,5,12,16...|             (93690,[0,5,12,16...|[-87.310165266251...|[1.17183117637695...|       1.0|\n",
      "|  Hey ya ll Every...|          Negative|  1.0|[, , hey, ya, ll,...|  [, , hey, ya, ll,...|      (93690,[0,4,8,12,...|             (93690,[0,4,8,12,...|[401.730808266680...|[1.0,6.1802631744...|       0.0|\n",
      "|  How will this a...|          Positive|  0.0|[, , how, will, t...|  [, , affect, unab...|      (93690,[0,29,131,...|             (93690,[0,29,131,...|[226.566122344780...|[1.0,9.4159137852...|       0.0|\n",
      "|  New Podcast Las...|           Neutral|  2.0|[, , new, podcast...|  [, , new, podcast...|      (93690,[0,37,48,2...|             (93690,[0,37,48,2...|[86.7545681739204...|[1.0,3.6850427494...|       0.0|\n",
      "|  PLEASE RT Aston...|Extremely Positive|  3.0|[, , please, rt, ...|  [, , please, rt, ...|      (93690,[0,4,26,29...|             (93690,[0,4,26,29...|[261.728808571364...|[1.0,2.9176749945...|       0.0|\n",
      "|  Panic buying is...|          Negative|  1.0|[, , panic, buyin...|  [, , panic, buyin...|      (93690,[0,4,23,47...|             (93690,[0,4,23,47...|[238.779277734027...|[1.0,4.2539260114...|       0.0|\n",
      "|  Please don t pa...|          Negative|  1.0|[, , please, don,...|  [, , please, pani...|      (93690,[0,19,23,3...|             (93690,[0,19,23,3...|[125.261787195739...|[0.99999999986021...|       0.0|\n",
      "|  Stop   Fucking ...|          Negative|  1.0|[, , stop, , , fu...|  [, , stop, , , fu...|      (93690,[0,60,316,...|             (93690,[0,60,316,...|[-56.698223576318...|[1.00844955601782...|       4.0|\n",
      "|  Support Ken by ...|          Negative|  1.0|[, , support, ken...|  [, , support, ken...|      (93690,[0,4,12,16...|             (93690,[0,4,12,16...|[282.657919117868...|[1.0,2.2580363073...|       0.0|\n",
      "|  The gov of is c...|          Positive|  0.0|[, , the, gov, of...|  [, , gov, calling...|      (93690,[0,4,8,12,...|             (93690,[0,4,8,12,...|[29.4532622017253...|[7.38714601185520...|       1.0|\n",
      "|  What should I d...|          Positive|  0.0|[, , what, should...|  [, , m, buying, h...|      (93690,[0,2,19,47...|             (93690,[0,2,19,47...|[67.3056340138797...|[1.0,3.2767547384...|       0.0|\n",
      "|  Why are people ...|Extremely Negative|  4.0|[, , why, are, pe...|  [, , people, pani...|      (93690,[0,8,10,23...|             (93690,[0,8,10,23...|[8.14324046021592...|[1.57066998963694...|       4.0|\n",
      "|  bravo Supermark...|           Neutral|  2.0|[, , bravo, super...|  [, , bravo, super...|      (93690,[0,5,81,16...|             (93690,[0,5,81,16...|[163.615419016122...|[1.0,6.6818967752...|       0.0|\n",
      "|     too accurate 19|           Neutral|  2.0|[, , too, accurat...|    [, , accurate, 19]|      (93690,[0,12,5926...|             (93690,[0,12,5926...|[-28.433591821104...|[1.60555954055353...|       2.0|\n",
      "| A lot of our fam...|          Positive|  0.0|[, a, lot, of, ou...|  [, lot, families,...|      (93690,[0,4,33,54...|             (93690,[0,4,33,54...|[51.4121627675110...|[5.47972302461281...|       1.0|\n",
      "| A special shoppi...|Extremely Positive|  3.0|[, a, special, sh...|  [, special, shopp...|      (93690,[0,13,15,5...|             (93690,[0,13,15,5...|[63.8140878165811...|[0.99999996485038...|       0.0|\n",
      "+--------------------+------------------+-----+--------------------+----------------------+--------------------------+---------------------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prediction test data\n",
    "predictions = lr_model.transform(test_df)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HqMxQYzcF3ps",
    "outputId": "3f5bc83a-3615-4b45-e411-bb6314271de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.407693\n",
      "Test Error = 0.592307 \n"
     ]
    }
   ],
   "source": [
    "# Import evaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % (accuracy))\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP_Q1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
